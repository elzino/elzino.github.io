<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="https://elzino.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://elzino.github.io/" rel="alternate" type="text/html" /><updated>2020-12-24T14:27:12+00:00</updated><id>https://elzino.github.io/</id><title type="html">ELZINO PROJECT</title><subtitle>Small blog for logging my life</subtitle><author><name>Jinho Lee</name><email>elzinomaster@gmail.com</email></author><entry><title type="html">Collaborative Filtering for Implicit Feedback Datasets 리뷰</title><link href="https://elzino.github.io/papers/2020-12-24/collaborative-filtering-for-implicit-feedback-datasets" rel="alternate" type="text/html" title="Collaborative Filtering for Implicit Feedback Datasets 리뷰" /><published>2020-12-24T00:00:00+00:00</published><updated>2020-12-24T00:00:00+00:00</updated><id>https://elzino.github.io/papers/2020-12-24/collaborative-filtering-for-implicit-feedback-datasets</id><content type="html" xml:base="https://elzino.github.io/papers/2020-12-24/collaborative-filtering-for-implicit-feedback-datasets">&lt;p&gt;논문 링크 : &lt;a href=&quot;http://yifanhu.net/PUB/cf.pdf&quot;&gt;pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;최근 추천 시스템에 관심을 갖게 되었는데요. 이 논문을 다들 추천해주셔서 읽고 정리해보게 되었습니다.&lt;/p&gt;

&lt;p&gt;논문은 제목에서 나와있듯이 Implicit feedback으로 구성된 dataset에서 어떻게 collaborative filtering을 적용해야하는지 방법론을 제시합니다. 그 과정에서 배경지식, Implicit feedback의 특징 등도 잘 정리해놓아서 처음 추천 시스템을 공부하시는 분들이 읽으시면 많은 도움이 될 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;explicit-feedback-vs-implicit-feedback&quot;&gt;Explicit feedback vs Implicit feedback&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Explicit feedback&lt;/em&gt;은 유저가 상품에 대해 직접 평가를 남긴 경우를 의미합니다. 예를들어 쿠팡에서 상품을 산 후 후기를 별점으로 남기는 경우, 넷플릭스에서 영화를 본 후 평점을 남기는 경우 등이 이에 해당합니다.&lt;/p&gt;

&lt;p&gt;반면에 &lt;em&gt;implicit feedback&lt;/em&gt;은 유저가 명시적으로 상품에 대해 평가를 한 것이 아니라 유저의 행동을 관찰해 의견을 간접적으로 반영하는 것을 의미합니다. 예를 들어 구매 기록, 검색 기록 등이 이에 해당됩니다.&lt;/p&gt;

&lt;p&gt;이 논문 이전에는 많은 연구가 explicit feedback에 한해서 이루어졌는데요. 이는 explicit feedback이 데이터를 활용하기 더 편하기 때문입니다. 하지만 실제 산업에서 추천 시스템을 적용할 때는 explicit feedback이 존재하지 않거나 implicit feedback에 비해 데이터가 훨씬 적은 경우가 많습니다. 따라서 implicit feedback에서의 추천 시스템 연구가 중요하다고 논문은 강조하고 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;characteristics-of-implicit-feedback&quot;&gt;Characteristics of implicit feedback&lt;/h2&gt;
&lt;p&gt;Implicit feedback은 explicit feedback과 비교했을 때 다른 중요한 특징들을 갖고 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;no-negative-feedback&quot;&gt;No negative feedback&lt;/h3&gt;
&lt;p&gt;implicit feedback은 유저의 구매 기록등을 관찰함으로써 유저가 좋아할 거 같은 아이템들은 예측할 수 있습니다. 하지만 유저가 좋아하지 않는 아이템들은 예측하기 쉽지 않습니다. 예를들어 유저가 어떤 상품을 사지 않았을 때, 그 상품을 좋아하지 않아서 사지 않았을 수도 있고, 아니면 존재 자체를 몰라서 사지 않았을 수도 있습니다. explicit feedback의 경우 평점을 낮게 줌으로써 어떤 상품을 싫어하는지도 알 수 있는 것에 비교하면 큰 차이입니다. 따라서 explicit feedback은 평점이 있는 유저-상품 relationship만 dataset으로 사용을 합니다. 이에 반해 implicit feedback은 missing data(위 예시에서 구매기록이 없는 경우)도 사용을 해야합니다. 이런 missing data들이 negative feedback일 것이라고 기대를 하고 사용을 하게 됩니다.&lt;/p&gt;

&lt;h3 id=&quot;implicit-feedback-is-inherently-noisy&quot;&gt;Implicit feedback is inherently noisy&lt;/h3&gt;
&lt;p&gt;우리가 유저의 행동을 통해 선호를 예측할 수는 있지만, 이것이 유저의 상품에 대한 positive view를 보장하지는 않습니다. 예를 들어 상품을 선물용으로 샀을 수도 있고, 상품을 산 이후에 실망을 했을 수도 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;the-numerical-value-of-explicit-feedback-indicates-preference-whereas-the-numberical-value-of-implicit-feedback-indicates-confidence&quot;&gt;The numerical value of explicit feedback indicates &lt;em&gt;preference&lt;/em&gt;, whereas the numberical value of implicit feedback indicates &lt;em&gt;confidence&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;explicit feedback은 rating의 값에 따라 선호를 나타냅니다. 예를 들어 5점은 정말 좋아하는 경우를 나타내고, 1점은 정말 싫어하는 경우를 나타내죠. 하지만 implicit feedback의 수치는 어떠한 행동의 빈도를 나타냅니다. 예를 들어 유저가 특정 상품을 몇번 구매했는지를 나타내죠. 여기서는 더 큰 값일 수록 더 큰 선호를 나타내지 않습니다. 가장 좋아하는 영화가 한 번 본 영화일수도 있기 때문이죠. 그럼에도 불구하고 implicit feedback 수치는 유용합니다. 이것은 우리가 그 특정 기록에 대해 얼마나 확신을 갖을 수 있는지 말해주기 때문입니다. 한 번만 일어난 event는 유저의 선호와 관련이 없을 수 있지만, 여러번 반복해서 일어나는 event는 필연적으로 user의 의견을 반영하고 있기 때문입니다.&lt;/p&gt;

&lt;h3 id=&quot;evaluation-of-implicit-feedback-recommender-requires-appropriate-measures&quot;&gt;Evaluation of implicit-feedback recommender requires appropriate measures&lt;/h3&gt;
&lt;p&gt;explicit feedback과 같이 유저가 상품에 대한 수치적 점수를 명시하는 경우는 mean square error 등을 통해 추천의 성능을 쉽게 측정할 수 있습니다. 하지만 implicit feedback의 경우 모호한 점이 많습니다.&lt;/p&gt;

&lt;h2 id=&quot;previous-work&quot;&gt;Previous work&lt;/h2&gt;
&lt;p&gt;여기서는 기존에 사용되던 CF(collaborative filtering) 방법에 대해 간략히 요약하고 넘어가겠습니다. CF는 과거의 user와 item간의 관계를 분석함으로써 미래의 user와 item 간의 intercation을 예측합니다.&lt;/p&gt;

&lt;h3 id=&quot;neighborhood-models&quot;&gt;Neighborhood models&lt;/h3&gt;
&lt;p&gt;Negihborhood model은 크게 user-oriented method와 item-oriented method로 구성되어 있습니다. user-oriented method는 비슷한 유저의 기록을 바탕으로 unknown rating을 예측합니다. 반면 item-orietned method는 유저가 이미 평점을 내린 다른 item들과 유사도를 이용해서 unknown rating을 예측합니다.&lt;/p&gt;

&lt;p&gt;item-oriented method를 수식으로 나타내보겠습니다. 현재 우리의 목표는 유저 u가 item i에 얼마만큼의 평점 \( r_{ui} \)를 매길지 예측하는 것입니다. 먼저 유저 u가 rating한 item 중 유사도를 이용해서 item i와 가장 유사한 k개를 뽑습니다. 이를 \( S^k(i;u) \)라고 하겠습니다. \( r_ui \)의 예측값은 유사한 item들의 평점의 weighted average로 계산됩니다. 수식은 다음과 같습니다.
\[ \hat{r}_{ui} = \frac{\sum_{j \in S^k(i;u)}{s_{ij}r_{uj}}}{\sum_{j \in S^k(i;u)}{s_{ij}}} \]&lt;/p&gt;

&lt;h3 id=&quot;latent-factor-models&quot;&gt;Latent factor models&lt;/h3&gt;
&lt;p&gt;Latent factor model은 관측된 rating들을 잘 설명하는 latenet feature들을 찾는 것을 목표로 합니다. 각 user를 \( x_u \in \mathbb{R}^f \)에, 각 item을 \( y_i \in \mathbb{R}^f \)에 매핑하고 내적을 통해 예측합니다. \( \hat{r}_{ui} = x^T_uy_i \).
\[ \min_{x,y} \sum_{r_{ui}\ is\ known}{(r_{ui} - x^T_u y_i)^2 + \lambda(\lVert x_u \rVert^2 + \lVert y_i \rVert^2)}  \]
여기서 lambda는 regularization을 위해 존재합니다. parameter는 보통 stochastic gradient descent를 통해 update 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;our-model&quot;&gt;Our model&lt;/h2&gt;

&lt;p&gt;이제 본격적으로 논문에서 제안한 모델을 소개해드리겠습니다. 제일 중요한 부분은 implicit feedback의 특징을 잘 반영하기 위해 preference와 confidence를 도입한 것입니다. 이제 하나씩 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;preference는 user의 선호 여부를 나타내는 binary variable입니다. \( p_{ui}\)는 다음과 같이 \( r_{ui} \)의 값을 이진화함으로써 얻어집니다.
\[
  p_{ui} =
    \begin{cases}
      1 &amp;amp; r_{ui} &amp;gt; 0 \cr
      0 &amp;amp; r_{ui} = 0
    \end{cases}
\]
여기서는 0보다 크면 preference를 1로 설정하였지만 이는 task에 따라 다르게 설정할 수 있습니다. threshold의 개념으로 생각하면 될 것 같습니다.&lt;/p&gt;

&lt;p&gt;confidence \( c_{ui} \)는 우리가 preference \( p_{ui} \)에 얼마나 자신이 있는지를 수치로 나타냅니다. 만약 \( r_{ui} \)가 높다면 user가 그 상품에 대해 반복적으로 구매 혹은 시청을 했다는 것입니다. 즉 \( r_{ui} \)가 높다는 것은 user가 그 상품을 선호한다고 더 확신할 수 있게 해줍니다. 합리적인 \( c_{ui} \) 선택은 다음과 같습니다.
\[ c_{ui} = 1 + \alpha r_{ui} \]
여기 alpha값은 hyperparameter로 실험을 통해 잘 작동하는 값으로 설정해주면 됩니다. 후에 서술하겠지만 \( c_{ui} \)는 다른 방법으로도 설정해도 됩니다. 저자는 또 다른 방법으로 \( c_{ui} = 1 + \alpha \log(1 + r_{ui} / \epsilon) \) 과 같은 방법을 제안합니다.&lt;/p&gt;

&lt;p&gt;논문의 모델도 latent factor model과 유사하게 각 user를 \( x_u \in \mathbb{R}^f \)에, 각 item을 \( y_i \in \mathbb{R}^f \)에 매핑해서 이 둘의 내적이 preference를 나타내도록 하는 것입니다:\( \hat{p}_{ui} = x^T_uy_i \). 이를 다음과 같은 식을 최소화 하는 x, y들을 찾아야 합니다.
\[ \min_{x,y} \sum_{u, i}{c_{ui}(p_{ui} - x^T_u y_i)^2 + \lambda(\lVert x_u \rVert^2 + \lVert y_i \rVert^2)}  \]
위 식을 최소화 하기 위해 user-factor나 item-factor를 고정한 후 이차식에 대해 최적화를 진행하는 alternating-least-square 방법으로 문제를 풉니다.&lt;/p&gt;

&lt;p&gt;latent factor model과 비교했을때 confidence와 preference의 개념이 추가된것을 확인할 수 있습니다. 또한 rating이 존재하는 relation들만 고려하는 것이 아니라 모든 가능한 u, i pair에 대해 optimization을 진행하게 됩니다. 따라서 연산량이 크게 증가하게 되고 효율적인 최적화 방법이 필요해집니다. 이를 논문에서 효율적으로 최적화 하는 방법 또한 소개합니다. 이 부분은 따로 정리하지 않겠습니다. 관심 있으신 분들은 논문을 보시면 좋을 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;explanning-recommendation&quot;&gt;Explanning recommendation&lt;/h2&gt;
&lt;p&gt;좋은 추천 모델은 왜 그런 item들을 추천하였는지 설명할 수 있어야 합니다. item-oriented neighborhood model 방법은 상대적으로 설명이 쉬운 반면, latent factor model은 그런 설명을 하기가 어렵습니다. 하지만 저자는 제안한 모델을 설명가능하게 만들고자 식을 적당히 조절을 해서 다음과 같이 나타냅니다.
\[ \hat{p}_{ui} = \sum_{j:r_{uj}&amp;gt;0}{s^u_{ij}c_{uj}} \]
이때 \( c_{uj} \)는 유저가 아이템을 얼마나 좋아하는지 나타내는 정도, \( s^u_{ij} \)는 아이템간의 유사도로 해석을 합니다.
이 방법을 사용하면 item-oriented neighborhood model과 유사하게 설명을 할 수 있게 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;experimental-study&quot;&gt;Experimental study&lt;/h2&gt;
&lt;p&gt;논문에서는 텔레비젼의 시청기록을 dataset으로 이용해 실험을 진행하였습니다. 4주간의 시청기록을 바탕으로 training set을 구성하였고 그 직후의 1주간의 시청기록을 test set으로 사용하였습니다.
유저가 잘 모르는 프로그램을 추천해주는 것이 중요하기 때문에 성능 측정할때 test set에서 training set에서 이미 본 프로그램들은 지운 점이 인상깊었습니다. 이 외에도 \( r^t_{ui} \)가 0.5 미만인 것은 제외하고 연달아 시청한 경우 가중치를 곱해 더하는 등 여러가지 추가 조정을 적용합니다. 관심있으신 분들은 논문을 찾아보시는 것을 추천드립니다.
\[ \bar{rank} = \frac{\sum_{u,i}{r^t_{ui}rank_{ui}}}{\sum_{u,i}{r^t_{ui}}} \]
위 metric을 이용하여 개인화 추천 없이 인기순 대로 추천을 하는 popularity, neighborhood method와 결과를 비교합니다.
&lt;img src=&quot;https://www.dropbox.com/s/0ji3u8u19mfyzqz/result.png?raw=1&quot; alt=&quot;result&quot; width=&quot;500px&quot; /&gt;
실험 결과 논문의 방법인 factor 모델이 가장 좋은 성능을 보이는 것을 알 수 있습니다. 또한 dimmension을 키울수록 더 성능이 좋아지는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Implicit feedback 및 추천 시스템의 기초에 대해 잘 정리되어 있는 논문이라고 생각합니다. 논문을 읽고 정리하면서 많이 배울 수 있어 좋았습니다.&lt;/p&gt;</content><author><name>Jinho Lee</name><email>elzinomaster@gmail.com</email></author><category term="deep learning" /><category term="recommendation system" /><category term="implicit feedback" /><summary type="html">논문 링크 : pdf</summary></entry><entry><title type="html">인도 여행기</title><link href="https://elzino.github.io/life/2020-08-23/india-travel" rel="alternate" type="text/html" title="인도 여행기" /><published>2020-08-23T00:00:00+00:00</published><updated>2020-08-23T00:00:00+00:00</updated><id>https://elzino.github.io/life/2020-08-23/india-travel</id><content type="html" xml:base="https://elzino.github.io/life/2020-08-23/india-travel">&lt;p&gt;핸드폰을 정리하던 중 인도에서 매일 자기 전에 썼던 일기를 발견했습니다. 다시 읽어보니 추억들이 떠오르고, 인도가 그리워져 사진을 조금 추가해 정리해봤습니다. 새벽에 인도에 도착한 0일차와 마지막날은 일기가 없습니다. 재밌게 읽어주세요. :smile:
&lt;br /&gt;(이 글은 &lt;a href=&quot;https://www.notion.so/8efb7670891a4608a272be397828177c&quot; target=&quot;_blank&quot;&gt;노션에서 쓴 글&lt;/a&gt;을 다시 옮긴 글입니다. 노션에서 보는 걸 더 추천드려요!)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/2020-08-23/india-travel/day1/&quot;&gt;인도 1일차 - 뉴델리 (18.03.10)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/2020-08-23/india-travel/day2/&quot;&gt;인도 2일차 - 뉴델리 (18.03.11)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/2020-08-23/india-travel/day3/&quot;&gt;인도 3일차 - 바라나시 (18.03.12)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/2020-08-23/india-travel/day4/&quot;&gt;인도 4일차 - 바라나시 (18.03.13)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/2020-08-23/india-travel/day5/&quot;&gt;인도 5일차 - 바라나시 (18.03.14)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/2020-08-23/india-travel/day6/&quot;&gt;인도 6일차 - 자이살메르 (18.03.15)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/2020-08-23/india-travel/day7/&quot;&gt;인도 7일차 - 자이살메르 (18.03.16)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/2020-08-23/india-travel/day8/&quot;&gt;인도 8일차 - 조드푸르 (18.03.17)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/2020-08-23/india-travel/day9/&quot;&gt;인도 9일차 - 조드푸르 (18.03.18)&lt;/a&gt;&lt;/p&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;인도 꿀팁 1&lt;/b&gt;&lt;/summary&gt;
강한 햇빛을 가리려고 가져간 밀집모자가 정말 큰 인기를 끌었다. 이유는 나도 모르겠다. Nice hat을 외치며 모자를 빌려가 사진을 찍은 인도인만 10명정도 되는 거 같다. 타지마할에서는 웨딩 촬영을 하는 인도인이 빌려가 웨딩드레스와 함께 밀짚모자를 쓰고 사진을 찍기도 했다. ㅋㅋㅋ 알 수 없는 인도감성이다.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;인도 꿀팁 2&lt;/b&gt;&lt;/summary&gt;
한국에서 왔다고 하면 무조건 North인지 South인지 묻는다. North라고 하면서 농담 좀 하면 이미 친구가 되어 있다.
&lt;/details&gt;</content><author><name>Jinho Lee</name><email>elzinomaster@gmail.com</email></author><category term="india" /><category term="travel" /><summary type="html">핸드폰을 정리하던 중 인도에서 매일 자기 전에 썼던 일기를 발견했습니다. 다시 읽어보니 추억들이 떠오르고, 인도가 그리워져 사진을 조금 추가해 정리해봤습니다. 새벽에 인도에 도착한 0일차와 마지막날은 일기가 없습니다. 재밌게 읽어주세요. :smile: (이 글은 노션에서 쓴 글을 다시 옮긴 글입니다. 노션에서 보는 걸 더 추천드려요!)</summary></entry><entry><title type="html">2019 회고, 2020 목표</title><link href="https://elzino.github.io/life/2020-01-07/review-about-2018-and-plan-for-2019" rel="alternate" type="text/html" title="2019 회고, 2020 목표" /><published>2020-01-07T00:00:00+00:00</published><updated>2020-01-07T00:00:00+00:00</updated><id>https://elzino.github.io/life/2020-01-07/review-about-2018-and-plan-for-2019</id><content type="html" xml:base="https://elzino.github.io/life/2020-01-07/review-about-2018-and-plan-for-2019">&lt;p&gt;&lt;a href=&quot;https://elzino.tistory.com/10?category=670066&quot; target=&quot;_blank&quot;&gt;지난 2018회고, 2019 계획&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2019년이 가고 2020년이 왔습니다. 오지 않을 것 같던 전역도 오고 복학이 코 앞이네요. 2019년은 저에게 어떤 일년이었는지 되돌아보고 2020년의 계획을 세우고자 이 글을 쓰게 되었습니다.&lt;/p&gt;

&lt;h1 id=&quot;2019-회고&quot;&gt;2019 회고&lt;/h1&gt;
&lt;p&gt;2019년에는 크게 4가지에 집중한 것 같습니다. 군대, 딥러닝, PS, 운동&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.dropbox.com/s/p73fme17102v23o/2018%20logs.jpg?raw=1&quot; alt=&quot;2018 logs&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;군대-20180423--20191219&quot;&gt;군대 (2018.04.23 ~ 2019.12.19)&lt;/h2&gt;
&lt;p&gt;오지 않을 것만 같았던 전역을 했습니다. 카투사로 복무해서 남들보다 좋은 여건에서 근무할 수 있었습니다. 미군들과 같이 훈련받고 생활하면서 다양한 문화를 겪고 생각의 폭을 넓힐 수 있었습니다. 영어도 조금 늘었고 체력도 강해졌습니다. 가장 큰 훈련인 거너리 훈련에 한 달간 참여했습니다. 씻지도 못하고 120mm 박격포를 쏘고, 경계 근무를 서며 밤을 새는 등 잊지 못할 추억을 쌓았습니다. EIB(Expert Infantryman Badge) 훈련은 가장 고됐지만 가장 보람 있었습니다. 잘 짜여진 프로그램 하에서 훈련 받을 수 있었습니다. 하반기에는 시니어카투사로서 중대 카투사를 책임지는 역할을 맡았습니다. 복무 당시에는 너무 답답하고 힘들었지만 한층 더 성장할 수 있는 시간이었습니다. 주말 외박, 개인 정비 시간을 활용해 저에게 더 집중할 수 있던 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;딥피스트20181229--20190608&quot;&gt;딥피스트(2018.12.29 ~ 2019.06.08)&lt;/h2&gt;
&lt;p&gt;지원 당시 부족한 실력이었음에도 받아주셔서 즐겁게 활동할 수 있었던 서울대학교 딥러닝 학회입니다. 입문자반분들과 CS231n 수업을 듣고 과제를 하고, 논문들을 읽고 발표했습니다. 매주 진행되는 딥피스트 호스팅에서는 폭 넓은 분야의 발표를 들을 수 있었습니다. 딥러닝 분야에 대한 관심과 실력을 키울 수 있는 좋은 기회였습니다. 다만 훈련 기간이 많이 겹쳐서 자주 빠진 점이 아쉬움으로 남습니다.&lt;/p&gt;

&lt;h2 id=&quot;강화학습-201902--201906&quot;&gt;강화학습 (2019.02 ~ 2019.06)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html&quot;&gt;David Silver 교수님의 강의&lt;/a&gt;를 들으면서 강화학습 공부를 시작했습니다.(진짜 명강이라고 생각합니다 강추! :+1:) 수학적 이론을 기반으로 진행되는 점에서 굉장히 흥미를 느꼈고 관련 논문들도 찾아 읽게 되었습니다.(openai의 &lt;a href=&quot;https://spinningup.openai.com/en/latest/&quot;&gt;spinning up&lt;/a&gt; 사이트 추천합니다) deep q learning과 policy gradient 방식들을 찾아 읽었으며 간단한 &lt;a href=&quot;https://github.com/elzino/DQN_Cartpole_Torch&quot;&gt;cartpole 환경에서 dqn&lt;/a&gt;도 구현했습니다. &lt;a href=&quot;https://github.com/elzino/A2C_Pytorch&quot;&gt;Atari 환경에서 A2C&lt;/a&gt;도 구현을 시도했지만 학습이 잘 진행이 되지 않아서 지금은 잠시 중단한 상태입니다. 하지만 구현과정에서 &lt;a href=&quot;https://github.com/openai/baselines/pull/915&quot;&gt;openai의 baselines에 contribute&lt;/a&gt;를 하는 값진 경험을 할 수 있었습니다.&lt;/p&gt;

&lt;h2 id=&quot;ps-공부-201906--201909&quot;&gt;PS 공부 (2019.06 ~ 2019.09)&lt;/h2&gt;
&lt;p&gt;A2C 구현 이후로 딥러닝이 아닌 다른 분야를 공부해보고 싶어 PS 공부를 시작했습니다. 구종만님이 지으신 &lt;a href=&quot;http://www.yes24.com/Product/Goods/8006522&quot;&gt;알고리즘 문제 해결 전략&lt;/a&gt;을 읽으며 공부하기 시작했습니다. 오랫동안 쓰지 않았던 C++도 다시 공부하게 되었습니다.&lt;/p&gt;

&lt;h2 id=&quot;카카오-블라인드-공채-201909&quot;&gt;카카오 블라인드 공채 (2019.09)&lt;/h2&gt;
&lt;p&gt;PS를 공부하던 중 카카오 블라인드 공채가 진행된다는 광고를 봤습니다. 제가 어느정도 실력이 되는지 테스트 하고 싶어 재미로 지원하게 되었습니다. &lt;a href=&quot;https://tech.kakao.com/2019/10/02/kakao-blind-recruitment-2020-round1/&quot;&gt;온라인 코딩 테스트&lt;/a&gt;에서 7문제 중 5문제를 풀어 합격했습니다! &lt;a href=&quot;https://tech.kakao.com/2019/10/21/kakao-blind-recruitment-2020-round2/&quot;&gt;오프라인 코딩 테스트&lt;/a&gt;에서는 팔로잉 추천 시스템 구현이 나왔는데 구현력이 중요한 테스트 같았습니다. 저는 어떻게 짜야 추천 성공률이 높을지 고민하다가 이미 매칭이 된 사람부터 추천해나가는 방법을 택해 짜봤습니다. 하지만 그 당시 파이썬이 익숙치 않았고 짧은 시간 안에 로직을 짜는 것을 많이 해보지 않아서 시간이 부족했습니다. 2문제 중 한 문제만 간신히 풀고 테스트를 마쳤습니다. 당연히 떨어진 줄 알았는데 붙었다는 메일을 받고 카카오 브레인의 테스트를 마저 보게 되었습니다. &lt;a href=&quot;https://elzino.github.io/papers/2019-11-21/radam&quot;&gt;RAdam 논문&lt;/a&gt;을 요약하고 코드를 개선하는 것이었는데 여기서 떨어졌습니다ㅠ 저가 어느정도 수준인지 가늠해 볼 수 있었고 즐겁게 참여한 행사였습니다.&lt;/p&gt;

&lt;h2 id=&quot;네이버-ai-해커톤-201909--201910&quot;&gt;네이버 AI 해커톤 (2019.09 ~ 2019.10)&lt;/h2&gt;
&lt;p&gt;네이버에서 열린 해커톤에 대학교 동기와 참여해 100팀 중 9등의 성과를 거두었습니다!(&lt;a href=&quot;https://elzino.github.io/projects/2019-11-16/naver-ai-hackathon-review&quot;&gt;후기 링크&lt;/a&gt;) 스피치 분야는 처음 공부하게 되었는데 굉장히 흥미로웠습니다. 해커톤 중 네이버 멘토님께서 지금은 마우스, 키보드 입력으로 서비스를 실행하지만 앞으로는 음성으로 서비스를 시작할 것이라는 말이 감명 깊었습니다. beam-search, label-smooth 등 스피치 분야에서 쓰이는 테크닉 뿐 아니라 ensemble, fine-tuning 등 해커톤에서 많이 쓰이는 기법들을 공부하고 적용해봤습니다.&lt;/p&gt;

&lt;h2 id=&quot;건양대학교-헬스-데이터톤-201911&quot;&gt;건양대학교 헬스 데이터톤 (2019.11)&lt;/h2&gt;
&lt;p&gt;건양대학교 헬스 데이터톤에 참가해 우승을 했습니다!(&lt;a href=&quot;https://elzino.github.io/projects/2019-12-01/konyang-health-datathon&quot;&gt;후기 링크&lt;/a&gt;) 이런 외부 대회에서 상을 받는게 처음이라 너무 신기하고 행복했습니다. 안저 이미지를 분류하는 것이 주어진 과제였는데 논문들을 찾아보며 사전조사를 했습니다. 사실 모델을 적용할 때 특별한 테크닉 없이 진행했다고 생각하는데 좋은 성과가 나와 놀랐습니다.&lt;/p&gt;

&lt;h2 id=&quot;spl-랩인턴-201912--202002&quot;&gt;SPL 랩인턴 (2019.12 ~ 2020.02)&lt;/h2&gt;
&lt;p&gt;전병곤 교수님의 소프트웨어 플랫폼 랩에서 인턴을 하게 되었습니다. 딥러닝 분산 학습을 처음으로 접하게 되었습니다. 기존에 연구실에서 개발한 parallax를 tensorflow 2.0에서도 잘 작동하게 만드는 task를 맡게 되었습니다. 처음으로 대학원 생활을 체험보는 거라 많이 배워갈 거라고 기대하고 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;2020-목표&quot;&gt;2020 목표&lt;/h1&gt;

&lt;h2 id=&quot;운동&quot;&gt;운동&lt;/h2&gt;
&lt;p&gt;전역 후에도 꾸준히 운동을 하려고 합니다. 2020년 안에 75키로까지 증량을 하면 좋겠습니다. 또한 3대 400을 달성해보고 싶습니다.&lt;br /&gt;
테니스도 마저 배우고 싶습니다. 짧게 배우고 입대를 해야해서 아쉬웠는데 테니스 수업을 듣고, 동아리에 들어가서 배우고자 합니다.&lt;/p&gt;

&lt;h2 id=&quot;영어&quot;&gt;영어&lt;/h2&gt;
&lt;p&gt;카투사에서 쌓은 영어 실력을 꾸준히 유지하고 더 늘리고 싶습니다. 이를 위해 스누버디에 지원해 합격한 상태입니다. 1학기에 외국인 친구들을 많이 사귀고 같이 재밌게 놀고자 합니다. 넷플릭스도 꾸준히 볼 생각이고 여유가 있으면 토플 혹은 gre 공부도 해보고 싶습니다.&lt;/p&gt;

&lt;h2 id=&quot;학교-생활&quot;&gt;학교 생활&lt;/h2&gt;
&lt;h3 id=&quot;1학기&quot;&gt;1학기&lt;/h3&gt;
&lt;p&gt;학교에 잘 적응하고 싶습니다. 동아리, 학점 모두 잘 챙기고 싶습니다. 학점은 4점대가 목표입니다. 대학교 다니면서 4점대를 한 번은 받아봐야 뿌듯하게 남을 것 같습니다. 알고리즘 공부도 꾸준히 하려고 합니다. 관련 수업을 듣는 만큼 자투리 시간을 활용해서 종만북을 여러번 보려고 합니다.&lt;/p&gt;

&lt;h3 id=&quot;여름방학&quot;&gt;여름방학&lt;/h3&gt;
&lt;p&gt;여름 방학엔 인턴을 했으면 좋겠습니다. 지금 지원한 스위스 취리히 대학교 인턴이나, 네이버 클로바 인턴을 하면 좋겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;2학기&quot;&gt;2학기&lt;/h3&gt;
&lt;p&gt;2학기에는 컴퓨터 시스템 관련 과목들을 많이 들을 예정입니다. 전공 위주로 들을 계획이고 로우 레벨의 지식을 쌓는데 집중하려고 합니다.&lt;/p&gt;

&lt;h2 id=&quot;블로그&quot;&gt;블로그&lt;/h2&gt;
&lt;p&gt;꾸준히 블로그 글을 썼으면 좋겠습니다. 그동안 공부한 딥러닝 분야들도 정리하고, 추가로 관심 생기는 분야가 있으면 블로그에 정리하는 것을 습관화 했으면 좋겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;기타&quot;&gt;기타&lt;/h2&gt;
&lt;p&gt;운전 연습을 많이 해서 능숙해졌으면 좋겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;마치며&quot;&gt;마치며&lt;/h1&gt;
&lt;p&gt;2019년은 돌아봤을때 만족스러운 한 해였습니다. 2020년도 열심히 살아서 지금 목표한 바를 다 이루고 한 층 더 성장해 있고자 합니다.&lt;/p&gt;</content><author><name>Jinho Lee</name><email>elzinomaster@gmail.com</email></author><category term="hackathon" /><category term="deep learning" /><category term="medical image classification" /><summary type="html">지난 2018회고, 2019 계획</summary></entry><entry><title type="html">Scaling Distributed Machine Learning with the Parameter Server 리뷰</title><link href="https://elzino.github.io/papers/2020-01-04/scaling-distributed-machine-learning-with-the-parameter-server" rel="alternate" type="text/html" title="Scaling Distributed Machine Learning with the Parameter Server 리뷰" /><published>2020-01-04T00:00:00+00:00</published><updated>2020-01-04T00:00:00+00:00</updated><id>https://elzino.github.io/papers/2020-01-04/scaling-distributed-machine-learning-with-the-parameter-server</id><content type="html" xml:base="https://elzino.github.io/papers/2020-01-04/scaling-distributed-machine-learning-with-the-parameter-server">&lt;p&gt;논문 링크 : &lt;a href=&quot;https://www.cs.cmu.edu/~muli/file/parameter_server_osdi14.pdf&quot;&gt;pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;최근 딥러닝 분산 학습을 공부하면서 &lt;a href=&quot;https://www.quora.com/What-is-the-Parameter-Server&quot;&gt;parameter server framework&lt;/a&gt;에 대해 알게 되었습니다. Uber의 &lt;a href=&quot;https://towardsdatascience.com/visual-intuition-on-ring-allreduce-for-distributed-deep-learning-d1f34b4911da&quot;&gt;ring-Allreduce&lt;/a&gt;와는 다른 방법으로 분산 학습을 지원하고 있었습니다. Parameter Server를 다룬 논문들을 찾아보다가 가장 유명한 이 논문을 읽고 리뷰하게 되었습니다. 14년도에 나온 논문이라 GPU를 본격적으로 사용하기 전인 점을 고려하면서 보시면 조금 더 이해가 잘 될 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;이 논문에서는 서버에서 글로벌하게 파라미터들을 관리하는 파라미터 서버 프레임워크를 제안합니다.&lt;/li&gt;
  &lt;li&gt;이 프레임워크는 asynchronous data communication, flexible consistency models, elastic scalability, continuous fault tolerance를 지원합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;큰 규모의 머신러닝 학습이 중요해지면서 분산 학습은 점점 필수가 되어가고 있습니다. 하지만 많은 연산량과 큰 규모의 데이터 통신 때문에 세심한 시스템 디자인이 요구됩니다. 그 중 한 예로 워커 노드들간에 파라미터를 공유하고 계산할 때마다 파라미터를 업데이트를 하는 파라미터 서버 방법이 있습니다. 하지만 파라미터를 공유하기 위해서는 막대한 양의 대역폭(network bandwidth), 동기화(synchronization), 10% 정도의 failure rate를 가지고 있는 일반 클라우드에서도 fault tolerance를 갖춰야하기 때문에 어려운 점이 많습니다. 이 논문에서는 이러한 한계들을 극복한 새로운 파라미터 서버 프레임워크를 제안합니다.&lt;/p&gt;

&lt;h3 id=&quot;main-ideas&quot;&gt;Main Ideas&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Efficient communication: asynchronous communication을 통해 워커노드들이 기다리지 않고 연산 할 수 있게 해줍니다.&lt;/li&gt;
  &lt;li&gt;Flexible consistency models: Consistency를 알고리즘, 데이터에 따라서 조절할 수 있게 해주었습니다. 이를 통해 synchronization cost, latency를 줄이고 convergence와 trade-off 할 수 있게 되었습니다.&lt;/li&gt;
  &lt;li&gt;Elastic Scalability: 프레임워크를 다시 시작하지 않고 노드를 새롭게 추가하거나 제거할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;Fault Tolerance and Durability: 머신에 문제가 생기더라도 1초안에 복구할 수 있습니다. 이를 위해 Vector clock 방법을 이용합니다.&lt;/li&gt;
  &lt;li&gt;Ease of Use: 공유된 파라미터들이 벡터나 행렬로 표현되어 머신러닝에 적용하기 쉽게 되어있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;architecture&quot;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://www.dropbox.com/s/8z0wf0gb3858joe/high%20level%20architecture.png?raw=1&quot; alt=&quot;High level architecture&quot; /&gt;
파라미터 서버 노드들은 위 그림과 같이 서버 그룹과 워커 그룹으로 묶을 수 있습니다. 서버 노드들은 공유된 파라미터들을 저장하고 있습니다. 서버 노드들끼리는 파라미터 복제나 이동을 위해 서로 통신합니다. 서버 매니저는 노드의 작동 상태나 파라미터의 할당 등을 관리합니다. 워커 그룹은 각각 application을 돌립니다.&lt;br /&gt;
워커들은 일반적으로 할당 받은 학습 데이터를 저장하고 미분값과 같은 local 통계값을 통신합니다. 워커들은 오직 서버 노드와만 통신하고 워커끼리 통신하지는 않습니다. 각 워커 그룹에는 스케쥴러가 있는데 일을 할당하고 진척상황을 관리합니다. 워커가 추가 되거나 없어지면 스케쥴러가 끝나지 않은 일을 다시 할당합니다.&lt;br /&gt;
파라미터 서버는 namespace를 지원하는데 각 워커 그룹마다 같은 namespace를 사용할 수도 다른 namespace를 사용할 수도 있습니다. 이를 사용하면 여러 개의 워커 그룹이 같은 namespace를 사용해 동시에 학습할 수도 있습니다. 또한 namespace를 달리해 한 워커 그룹은 학습을 담당하고 다른 워커 그룹은 online service에 사용할 수도 있습니다.&lt;/p&gt;

&lt;p&gt;이제 아키텍쳐를 이루는 구성요소들이 뭐가 있는지 하나씩 살펴 보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;key-value-vectors&quot;&gt;Key-Value Vectors&lt;/h3&gt;
&lt;p&gt;기본적으로 모델을 이루는 파라미터들을 key, value를 이용해 표현할 수 있습니다. feature ID가 key가 되고 weight가 value가 될 것입니다. 그런데 이 프레임워크는 머신러닝에서 linear algebra object들을 주로 다룬다는 점에 주목합니다. 따라서 key, value를 이용해 파라미터들을 저장하는 동시에 key가 없는 부분들을 0으로 취급해 벡터와 행렬로 표현할 수 있게 합니다. 이를 통해 여러 선형 대수 연산들을 최적화 할 수 있게 합니다.&lt;/p&gt;

&lt;h3 id=&quot;range-push-and-pull&quot;&gt;Range Push and Pull&lt;/h3&gt;
&lt;p&gt;노드 간에 데이터를 주고 받을 때 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;push&lt;/code&gt;나 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pull&lt;/code&gt; 연산을 사용합니다. 이때 range를 사용하면 효율적으로 network bandwidth를 사용할 수 있습니다. Range 안에 있는 key들에 해당하는 value들을 보내고 받을 수 있습니다. gradient도 파라미터와 같은 key를 사용하므로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;w.push(R, g, destination)&lt;/code&gt; 과 같이 range를 사용해서 주고 받을 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;user-defined-functions-on-the-server&quot;&gt;User-Defined Functions on the Server&lt;/h3&gt;
&lt;p&gt;워커에서 데이터를 처리하는 것 뿐 아니라, 서버에서도 유저가 정의한 함수를 실행할 수 있습니다. regularizer나 proximal operator등을 계산할 때 유용하게 쓰일 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;asynchronous-tasks-and-dependency&quot;&gt;Asynchronous Tasks and Dependency&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://www.dropbox.com/s/zff86wsrds1j5if/async.png?raw=1&quot; alt=&quot;async&quot; /&gt;
push나 pull, 노드에서 실행되는 user-defined 함수 등을 통틀어 task라 합니다. Task는 기본적으로 asynchronous 하게 작동됩니다. caller는 callee로 부터 끝났다는 신호를 받으면 task가 끝난 것으로 표시합니다. callee는 task의 return 값을 받고 subtask들이 모두 끝나면 끝났다고 표시합니다. Task는 병렬적으로 실행되지만 dependency를 줄 수 있습니다. 위 그림에서 iter 10과 iter 11은 독립적으로 실행되었지만 iter 12는 iter 11이 끝난 후에 실행하게 했습니다. dependency는 알고리즘 및 다음 장에서 설명할 flexible consistency 구현에 사용됩니다.&lt;/p&gt;

&lt;h3 id=&quot;flexible-consistency&quot;&gt;Flexible Consistency&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://www.dropbox.com/s/jytneivur3vu9e4/flexible%20consistency.png?raw=1&quot; alt=&quot;flexible consistency&quot; /&gt;
독립적인 task들은 병렬적으로 CPU, disk, network bandwidth를 사용해 시스템 효율성을 높일 수 있습니다. 하지만 이것은 노드 간에 data inconsistency를 야기해 수렴 속도를 늦출 수 있습니다. inconsistency에 강한 몇몇 알고리즘이 있으므로 여러가지 요소들을 고려해서 consistency model을 정의하는게 최상의 방법일 것입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sequential: 모든 task들이 순차적으로 실행됩니다. single-thread 구현과 동일합니다.&lt;/li&gt;
  &lt;li&gt;Eventual: 모든 task들이 동시에 시작될 수 있습니다. 알고리즘이 delay에 강할 때만 사용하는 것을 추천합니다.&lt;/li&gt;
  &lt;li&gt;Bounded Delay: maximal delay time \( \tau \)를 정해 놓고 새로운 task가 \( \tau \)전에 실행된 모든 task들이 실행될 때까지 막습니다. \( \tau = 0 \)이면 sequential과 같고 \( \tau=\inf \)면 Eventual과 같습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;user-defined-filters&quot;&gt;User-defined Filters&lt;/h3&gt;
&lt;p&gt;파라미터 서버는 key, value 값을 선택적으로 보낼 수 있게 합니다. 예를 들어 기존 파라미터와 비교해서 특정값 이상의 변화가 있을 때만 보내는 significantly modified filter를 사용할 수 있습니다. 이 논문은 뒤의 실험에서 서버의 weight에 영향을 줄 거 같은 gradient만 보내는 KKT filter를 사용합니다.&lt;/p&gt;

&lt;h2 id=&quot;implementation-details&quot;&gt;Implementation details&lt;/h2&gt;
&lt;p&gt;구현 과정에서 사용된 기술들이 어떤 것들이 있는지 살펴보겠습니다.&lt;/p&gt;
&lt;h3 id=&quot;vector-clock&quot;&gt;Vector Clock&lt;/h3&gt;
&lt;p&gt;복잡한 dependency graph와 machine failure로부터 빠른 복구를 위해 각 key-value값 마다 vector clock을 사용해 시간을 기록합니다. 모든 key-value 값 마다 time을 저장하려면 큰 용량이 필요하지만 range를 사용한다는 점을 이용해 최적화 할 수 있습니다. unique한 range마다 vector clock을 하나씩 주는 방법을 사용합니다. 파라미터 서버가 처음 시작했을 때는 서버 노드마다 하나의 vector clock만 있을 것입니다. range가 쪼개질 때마다 최대 3개의 vector clock이 생기지만 range의 개수가 파라미터의 개수보다 훨씬 적으므로 효율적으로 vector clock을 저장할 수 있게 됩니다.&lt;/p&gt;

&lt;h3 id=&quot;messages&quot;&gt;Messages&lt;/h3&gt;
&lt;p&gt;메세지는 다음과 같이 range, key-value 값들, 그리고 vector clock으로 구성됩니다.
\[ [vc(\mathcal{R}), (k1, v1), …, (k_p, v_p)]\ k_j\ \in\ \mathcal{R}\ and\ j\ \in\ \{ 1, …,p \} \]
Range에 있지만 message에 포함되지 않은 key-value도 같은 timestamp를 갖게 업데이트 됩니다. 머신러닝에서 통신량은 굉장히 크므로 메세지를 압축하는 것이 필요합니다. 매번 같은 key list를 보내는 경우가 많을 것이기 때문에 key list를 캐싱해서 사용합니다. 또한 value 값들도 0이 아닌 값들만 보내도록 압축하는 fast Sanppy compression을 사용합니다.&lt;/p&gt;

&lt;h3 id=&quot;consistent-hashing&quot;&gt;Consistent Hashing&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://www.dropbox.com/s/safvxfqar4yb41k/consistent%20hashing.png?raw=1&quot; alt=&quot;consistent hashing&quot; /&gt;
파라미터 서버는 기존의 해쉬 테이블 방식과 비슷하게 key를 나눕니다. Hash ring위에 key와 서버 노드 id를 둬서 각각의 서버 노드가 자신에게 할당된 파리미터를 저장하도록 합니다. load balancing과 recovery를 위해 물리적으로 하나인 서버가 여러 가상의 서버로 나뉘기도 합니다. 서버 매니저가 keyspace의 분할과 분배를 관리합니다.&lt;/p&gt;

&lt;h3 id=&quot;replication-and-consistency&quot;&gt;Replication and Consistency&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://www.dropbox.com/s/v9e5ews21i2ssnp/replica%20generation.png?raw=1&quot; alt=&quot;replica generation&quot; /&gt;
각 서버 노드는 k개의 반시계 방향으로 이웃 노드들의 파라미터들을 복제해서 갖고 있습니다. 이때 원래 파라미터의 주인을 master, 복구를 위해 파라미터들을 복제해서 가지고 있는 노드들을 slave라 칭하겠습니다. master의 값이 바뀔 때마다 slave들의 값들도 synchronous하게 바꿉니다. 워커가 server에 push를 하면 slave까지 다 복제가 되어야 task가 완료됩니다. 이 때문에 delay가 생길 수 있습니다. 하지만 위 그림과 같이 여러 노드들에 의해 값이 바꼈을때 그 변화를 aggregate해서 한번에 복제해 communication을 최적화합니다. relaxed consistency 덕분에 delay가 생겨도 큰 영향을 받지 않을 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;server-node-management&quot;&gt;Server Node Management&lt;/h3&gt;
&lt;p&gt;fault tolerance와 dynamic scaling을 위해 노드들의 추가와 제거를 지원해야합니다. 서버 노드가 추가될 때 다음과 같은 과정을 통해 추가됩니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;서버 매니저가 새로운 노드에 key range를 할당합니다. 다른 노드들의 key range가 쪼개지거나 종료된 노드의 key range가 제거될 수 있습니다.&lt;/li&gt;
  &lt;li&gt;서버 노드가 할당된 데이터를 가져오고 slave로서 k개의 노드에서 복제할 데이터들을 가져옵니다. 데이터 복제는 아래와 같이 두 단계로 진행됩니다.
-데이터를 미리 복제합니다.
-데이터를 복제하는 동안 온 메세지들을 새로운 노드에게 보내줍니다.&lt;/li&gt;
  &lt;li&gt;서버 매니저가 노드의 추가를 알립니다.
서버 노드가 제거될 때도 비슷한 과정을 통해 제거합니다. 서버 매니저가 서버노드들을 지켜보면서 비정상적으로 종료된 노드가 있는지 확인합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;worker-management&quot;&gt;Worker Management&lt;/h3&gt;
&lt;p&gt;워커 노드를 추가하는 것은 서버노드를 추가하는 것보다 더 간단합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;태스크 스케쥴러가 새로운 워커에게 데이터를 할당합니다.&lt;/li&gt;
  &lt;li&gt;이미 존재하는 워커 노드들이나 네트워크 파일 시스템으로부터 데이터를 받아옵니다. 서버 노드와 달리 학습 데이터는 읽기만 하므로 메세지를 보내는 등의 추가 작업을 하지 않습니다.&lt;/li&gt;
  &lt;li&gt;태스크 스케쥴러가 변화를 알립니다.
프레임워크는 워커 노드를 복구할 지 말지 사용자에게 선택권을 줍니다. 이는 학습 데이터가 클 때 워커 노드를 복구하는 비용이 클 수 있기 때문입니다. 또한 학습 데이터 중 조금을 잃는 것은 모델 학습에 영향을 거의 주지 않기 때문입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;evaluation&quot;&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;저자는 여러가지 적용 예시들에서 파라미터 서버를 실험해봅니다. 자세한 실험 조건이나 결과를 알고 싶으신 분들은 논문을 참고하는 것을 추천드립니다.
&lt;img src=&quot;https://www.dropbox.com/s/8fucdcnhnvz7qes/convergence%20of%20sparse%20logistic%20regression.png?raw=1&quot; alt=&quot;convergence of sparse logistic regression&quot; /&gt;
위 실험은 세가지 시스템이 같은 objective value에 도달할 때 까지 걸리는 시간을 측정해본 것입니다. System A, System B에 비해 더 빨리 수렴한 것을 확인 할 수 있습니다. 심지어 System B와는 같은 알고리즘을 사용했지만 network traffic을 낮추고 relaxed consistency model을 사용해 더 좋은 성능을 보인 것을 확인할 수 있습니다.
&lt;img src=&quot;https://www.dropbox.com/s/pk2xefi7p5hz4c2/time%20per%20worker%20spent%20on%20computation%20and%20waiting.png?raw=1&quot; alt=&quot;time per worker spent on computation and waiting&quot; /&gt;
위 그래프는 relaxed consistency model 덕분에 워커 노드를 더 효율적으로 사용할 수 있게 됨을 보여줍니다. 전의 task들이 끝나는 것을 기다리지 않고 다음 것을 처리함으로써 delay를 최소화 할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;이 논문은 딥러닝 분산 학습 분야에서 사용되는 중요한 개념을 소개합니다. consistent hashing 같이 시스템적인 측면에서 좋은 테크닉들을 조화롭게 사용해 elastic scalability, fault tolerance와 같은 중요한 부분들을 지원합니다.&lt;/p&gt;

&lt;p&gt;후에 딥러닝 분산 학습에 큰 영향을 미친 논문을 읽고 요약해봐서 뜻 깊었습니다. 또한 딥러닝 분산 학습 프레임워크를 만들 때 어떤 점들을 고려해야 되는지 알 수 있어 좋았습니다.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/coinmonks/parameter-server-for-distributed-machine-learning-fd79d99f84c3#d24d&quot;&gt;Parameter Server for Distributed Machine learning&lt;/a&gt;&lt;/p&gt;</content><author><name>Jinho Lee</name><email>elzinomaster@gmail.com</email></author><category term="deep learning" /><category term="distributed deep learning" /><category term="parameter server" /><summary type="html">논문 링크 : pdf</summary></entry><entry><title type="html">[번역] 딥러닝 분산 학습을 알아보자(Intro to Distributed Deep Learning Systems)</title><link href="https://elzino.github.io/papers/2019-12-30/intro-to-distributed-deep-learning-systems" rel="alternate" type="text/html" title="[번역] 딥러닝 분산 학습을 알아보자(Intro to Distributed Deep Learning Systems)" /><published>2019-12-30T00:00:00+00:00</published><updated>2019-12-30T00:00:00+00:00</updated><id>https://elzino.github.io/papers/2019-12-30/intro-to-distributed-deep-learning-systems</id><content type="html" xml:base="https://elzino.github.io/papers/2019-12-30/intro-to-distributed-deep-learning-systems">&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://medium.com/@Petuum/intro-to-distributed-deep-learning-systems-a2e45c6b8e7&quot;&gt;Intro to Distributed Deep Learning Systems&lt;/a&gt;를 번역한 문서입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;번역이 익숙치 않아 글이 어색할 수 있는 점 이해해주세요.&lt;/p&gt;

&lt;h2 id=&quot;머신러닝-분산-학습이란&quot;&gt;머신러닝 분산 학습이란?&lt;/h2&gt;
&lt;p&gt;일반적으로 머신러닝 분산 학습(distributed machine learning, DML)은 컴퓨터 사이언스 전반의 여러 학문이 포함된 분야입니다. 이론적 영역(통계, &lt;a href=&quot;https://en.wikipedia.org/wiki/Computational_learning_theory&quot;&gt;학습이론&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Mathematical_optimization&quot;&gt;최적화&lt;/a&gt;), 알고리즘, &lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;머신러닝&lt;/a&gt;(&lt;a href=&quot;https://en.wikipedia.org/wiki/Deep_learning&quot;&gt;딥러닝&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Graphical_model&quot;&gt;그래프 모델&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;커널&lt;/a&gt;), &lt;a href=&quot;https://en.wikipedia.org/wiki/Distributed_computing&quot;&gt;분산 처리&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Computer_data_storage&quot;&gt;기억 장치&lt;/a&gt; 등이 포함됩니다. 이러한 각각의 분야들에서 수많은 주제들이 연구되고 있습니다. 또한 DML(머신러닝 분산 학습)은 빅데이터에 대한 처리 능력때문에 산업에서 폭 넓게 사용되고 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;머신러닝-분산-학습으로-해결하려는-문제가-무엇일까&quot;&gt;머신러닝 분산 학습으로 해결하려는 문제가 무엇일까?&lt;/h2&gt;
&lt;p&gt;DML(머신러닝 분산 학습)을 이해하는 가장 쉬운 방법은 연구분야를 4개로 쪼개서 살펴보는 것입니다. 하지만 각각의 분야가 겹칠 수 있다는 점 미리 이해해 주세요.&lt;/p&gt;

&lt;h3 id=&quot;1-통계-최적화-알고리즘을-어떻게-사용할까&quot;&gt;1. 통계, 최적화, 알고리즘을 어떻게 사용할까?&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h3&gt;
&lt;p&gt;대부분의 머신러닝 방법들은 training data에 대한 loss 함수를 최소화 하므로 다음 항목들을 고려해 학습을 진행합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;최적화 과정이 수렴하는데까지 얼마나 걸리는지, 즉 수렴 속도가 얼마인지&lt;/li&gt;
  &lt;li&gt;수렴된 솔루션이 얼마나 좋은지&lt;/li&gt;
  &lt;li&gt;좋은 솔루션을 위해 얼마나 많은 데이터가 필요한 지&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이러한 분야들을 연구하기 위해 연구자들은 &lt;a href=&quot;https://en.wikipedia.org/wiki/Mathematical_optimization&quot;&gt;최적화 이론&lt;/a&gt;과 &lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_learning_theory&quot;&gt;통계적 학습 이론&lt;/a&gt; 같은 이론적 분석을 이용합니다. 하지만 많은 컴퓨팅 자원이 주어지고 병렬, 분산 학습등을 이용해 학습 속도를 올리는 것이 목표인 large-scale의 머신러닝 관점에서 보면 위와 비슷해 보이지만 다른 항목들을 고려하게 됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;분산, 병렬 학습을 사용했을 때 우리의 모델이 원래 수렴했던 것과 똑같이 수렴하는 것이 보장되는 지&lt;/li&gt;
  &lt;li&gt;만약 아니라면 원래의 솔루션과 얼마나 다른지, 그리고 본질적인 최적해와 얼마나 다른지&lt;/li&gt;
  &lt;li&gt;좋은 수렴을 위해 다른 가정이나 조건들이 필요한 지&lt;/li&gt;
  &lt;li&gt;분산 학습을 사용하지 않았을 때와 비교해서 얼마나 빠른지, 그리고 어떻게 평가할 것인지&lt;/li&gt;
  &lt;li&gt;좋은 scailabilty와 좋은 수렴을 둘 다 만족하기 위해 어떻게 학습 과정을 디자인 할 것인지&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-분산-학습에-더-적합한-머신러닝-모델-혹은-알고리즘을-어떻게-사용할까&quot;&gt;2. 분산 학습에 더 적합한 머신러닝 모델 혹은 알고리즘을 어떻게 사용할까?&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/h3&gt;
&lt;p&gt;이 분야는 새로운 머신러닝 모델을 개발하거나 이미 존재하는 모델을 큰 데이터에 잘 학습하도록 조정하는 것들을 연구합니다.&lt;/p&gt;

&lt;h3 id=&quot;3-분산-머신러닝-모델을-어떻게-실생활에-적용할까&quot;&gt;3. 분산 머신러닝 모델을 어떻게 실생활에 적용할까?&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Computer_vision#Recognition&quot;&gt;이미지 분류&lt;/a&gt;와 같이 특정 모델이나 알고리즘의 scale-up을 요구하는 세부적인 적용 분야가 있습니다. 이러한 문제들에 솔루션들은 대부분 바로 제품에 쓰이기도 합니다.&lt;/p&gt;

&lt;h3 id=&quot;4-머신러닝의-규모를-키우기-위해서-어떻게-분산-병렬-컴퓨터-시스템을-개발할까&quot;&gt;4. 머신러닝의 규모를 키우기 위해서 어떻게 분산, 병렬 컴퓨터 시스템을 개발할까?&lt;/h3&gt;
&lt;p&gt;이 분야는 오히려 더 직관적입니다. 머신러닝 모델이나 알고리즘이 하나의 노드에서 계산 작업을 다 마치지 못했다면 더 많은 노드를 사용해서 분산 시스템을 개발하는 것을 시도해볼 수 있지요. 하지만 더 많은 자원을 사용하기 위해 고려해야 할 사항들이 많습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;일관성(Consistency) : 여러개의 노드들이 동시에 학습을 하고 있다면 어떻게 합쳐야 할까? 예를 하나의 문제를 푸는데 노드마다 갖고 있는 데이터 셋이 다르다면 어떻게 해야할까?&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Fault_tolerance&quot;&gt;Fault tolerance&lt;/a&gt; : 클러스터가 1000개의 노드로 구성되어 있는데 만약 그 중 하나가 망가지면 어떻게 할까? 아예 처음부터 다시 시작하지 말고 고칠 수 있는 방법이 있을까?&lt;/li&gt;
  &lt;li&gt;통신(Communication) : 머신러닝은 많은 I/O(디스크 읽기, 쓰기), 데이터 처리 작업을 포함합니다. 다양한 환경에서(single node local disk, distributed file systems, CPU I/O, GPU I/O 등등) 빠른 I/O와 non-blocking 데이터 처리 과정을 가능하게 하는 저장 시스템을 설계할 수 있을까?&lt;/li&gt;
  &lt;li&gt;자원 관리(Resource management) : 컴퓨터 클러스터를 만드는 것은 엄청나게 비싸기 때문에 많은 유저들에게 공유됩니다. 자원 사용률을 최대화 해서 모두의 요구를 만족시키려면 어떻게 클러스터를 관리하고 자원을 할당해야 할까?&lt;/li&gt;
  &lt;li&gt;프로그래밍 모델(Programming model) : 평소에 프로그래밍 한 것과 같은 방법으로 분산 머신러닝 프로그래밍 해야할까? 코드량을 줄이고 효율성을 향상시키는 새로운 프로그래밍 모델을 만들 수 있을까? 하나의 노드에서 프로그래밍 한 것과 같이 프로그래밍 하면 자동으로 확장시킬 수 있을까?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;대부분의 주류 머신러닝 소프트웨어들은 이러한 기술들에 집중하고 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;딥러닝-분산-학습에-대한-이해&quot;&gt;딥러닝 분산 학습에 대한 이해&lt;/h2&gt;
&lt;p&gt;딥러닝 분산 학습은 최근 다양한 분야에서 성과를 거두며 굉장히 중요해진 머신러닝 분산 학습의 작은 분야입니다. 딥러닝 분산 학습의 핵심이나 직면하고 있는 문제점들로 들어가기 전에 몇가지 알아야 할 용어들이 있습니다. 바로 데이터 병렬화(data parallelism)과 모델 병렬화(model parallelism) 입니다.&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h3 id=&quot;데이터-병렬화data-parallelism&quot;&gt;데이터 병렬화(Data parallelism)&lt;/h3&gt;
&lt;p&gt;데이터 병렬화(&lt;a href=&quot;https://en.wikipedia.org/wiki/Data_parallelism&quot;&gt;Data parallelism&lt;/a&gt;)는 데이터를 쪼개서 병렬성을 가능하게 하는 기술입니다. 데이터 병렬화를 사용하면 먼저 데이터를 worker machines(computational node)의 수 만큼 나눕니다. 그 다음 우리는 각 worker가 하나의 독립적인 조각을 갖게 하고 그 데이터에 대해 연산을 하도록 합니다. 우리는 병렬적으로 데이터를 읽는 여러개의 노드를 갖고 있기 때문에 하나의 노드를 사용할 때보다 더 많은 데이터를 읽을 수 있을 것입니다. 데이터 병렬화를 통해 처리량을 증가시킨 것입니다.&lt;/p&gt;

&lt;p&gt;여러개의 노드를 사용해 수렴 속도를 높이고자 하는 분산 딥러닝에서, 데이터 병렬화는 직관적입니다. 우리는 각각의 워커가 자신의 데이터 조각에 대해 학습(경사 하강법)을 진행하도록 하고 그것에 대해 파라미터 업데이트(gradient)를 하도록 합니다. 모든 노드들이 네트워크를 통해 파라미터 상태들을 동기화시켜 모두 같은 값을 갖도록 합니다. 동기화를 하는데 시간이 지나치게 오래 걸리지 않는 한 하나의 노드를 사용할 때보다 향상된 결과를 볼 수 있을 것입니다. 이 방법이 구글의 초기 딥러닝 시스템인 &lt;a href=&quot;https://en.wikipedia.org/wiki/TensorFlow#DistBelief&quot;&gt;DisBelief&lt;/a&gt;가 본질적으로 작동하는 방식입니다.&lt;/p&gt;

&lt;h3 id=&quot;모델-병렬화model-parallelism&quot;&gt;모델 병렬화(Model parallelism)&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/h3&gt;
&lt;p&gt;데이터 병렬화와 비교했을때, 모델 병렬화는 더 복잡하고 추상적인 개념입니다. 일반적으로, 모델 병렬화에서는 데이터가 아닌 모델을 여러개의 워커에 나눕니다. 예를 들어 우리가 행렬 인수분해(Matrix factorization)를 하려고 할 때, 행렬의 크기가 너무 크고 우리는 이 거대한 행렬의 모든 파라미터를 알고 싶다고 가정해봅시다. 모델 병렬화를 진행하기 위해 우리는 행렬을 작은 단위(부분 행렬)로 나누고 각각의 워커에게 나눠줄 것입니다. 하나의 워커에 있는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Random-access_memory&quot;&gt;RAM&lt;/a&gt;이 행렬의 파라미터를 담기에 충분하지 않다면 이 방법으로 여러 노드의 추가적인 램을 사용할 수 있게 됩니다. 다양한 노드들이 각각 행렬의 다른 부분들에 해당하는 일을 처리하기 때문에, 병렬적으로 계산할 때 속도 향상을 얻을 수 있게됩니다.&lt;/p&gt;

&lt;p&gt;여기서 모델을 어떻게 나눠야 할까? 라는 질문이 떠오르게 됩니다. 너무나도 다양한 머신러닝 모델들이 있고 각 모델들마다 성격과 특징이 또 다르기 때문에, 모델 병렬화를 구현하는 원칙적 방법은 없습니다.&lt;/p&gt;

&lt;h3 id=&quot;분산-딥러닝의-문제들&quot;&gt;분산 딥러닝의 문제들&lt;/h3&gt;
&lt;p&gt;데이터 병렬화는 학습 데이터의 양이 많아질 때 더 빠르게 데이터를 읽을 수 있어서 상당히 효과적입니다. 모델 병렬화는 모델의 크기가 하나의 노드로 처리하기에 너무 클 때 여러 노드들의 메모리를 사용할 수 있게 해주므로 잘 들어 맞습니다.&lt;/p&gt;

&lt;p&gt;이상적으로 분산 딥러닝에서 우리가 할당한 머신의 수만큼의 속도향상을 얻길 원합니다.(보통 확장성이란 지표로 부릅니다.) 조금 더 구체적으로 K개의 머신을 할당했다면, 우리의 시스템이 하나의 머신에서 작동할 때보다 K배 더 빠르게 작동한다면 K의 확장성 혹은 선형적 확장성을 가지고 있다고 말합니다. 이러한 시스템에서 선형적 확장성은 이상적인 목표입니다.&lt;/p&gt;

&lt;p&gt;하지만 동기화로 인한 오버헤드 때문에, 보통 하나의 노드에서 학습할 때보다 분산 컴퓨터 클러스터에서 학습할 때 더 오랜 시간이 걸립니다. 우리는 머신러닝 태스크의 수렴을 위해 계산이 끝날 때마다 여러 노드들에 대해 동기화를 하는데 추가로 시간을 사용해야 합니다. 실제로 동기화는 계산만큰 시간이 걸리거나 더 걸리기도 합니다.&lt;/p&gt;

&lt;p&gt;왜일까요? 가장 큰 이유는 다른 노드들보다 느리게 작동하는 특정 노드들이 있기 때문입니다. 그들을 동기화시키기 위해 빠른 노드가 느린 노드들이 일을 끝낼 때까지 기다려야 합니다. 시스템 성능은 항상 더 느린 노드들에 의해 결정됩니다. 이러한 경우에 K개의 머신을 같이 놓는 것은 음의 확장성을 보일 것이고 이것은 돈과 시간 낭비입니다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;각주&quot;&gt;각주&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;더 공부해보면 좋을 논문입니다.&lt;br /&gt;&lt;a href=&quot;http://www.cs.cmu.edu/~seunghak/SSPTable_NIPS2013.pdf&quot;&gt;More Effective Distributed ML via a Stale Synchronous Parallel Parameter Server&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;아래 논문들을 추천해드립니다.&lt;br /&gt;&lt;a href=&quot;https://arxiv.org/abs/1311.4780&quot;&gt;Asymptotically Exact, Embarrassingly Parallel MCMC, by Willie Neiswanger&lt;/a&gt;, Chong Wang, Eric P. Xing. UAI 2014.&lt;br /&gt;&lt;a href=&quot;https://arxiv.org/abs/1412.1576&quot;&gt;LightLDA: Big Topic Models on Modest Compute Clusters&lt;/a&gt;, by Jinhui Yuan, Fei Gao, Qirong Ho, Wei Dai, Jinliang Wei, Xun Zheng, Eric P. Xing, Tie-yan Liu, Wei-Ying Ma. WWW 2015.&lt;br /&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.02496&quot;&gt;SaberLDA: Sparsity-Aware Learning of Topic Models on GPUs&lt;/a&gt;, by Kaiwei Li, Jianfei Chen, Wenguang Chen, Jun Zhu. ASPLOS 2017. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;두개의 주목할만한 큰 규모의 분산 딥러닝 논문이 NIPS 2012와 2013 ICML에서 출판되었습니다.&lt;br /&gt;첫번째 논문은 구글의 내부 딥러닝 프레임워크의 첫번째 세대에 관해서 설명하고 있습니다. 두번째 논문은 실리콘밸리의 바이두를 이끌고 있는 Adam Coates가 쓴 논문입니다. 이 두 논문의 핵심 아이디어는 더 많은 연산 노드를 사용해 딥러닝 연산의 규모를 키우는 것입니다. 첫번째 논문은 데이터 병렬화 두번째 논문은 모델 병렬화를 사용했습니다.&lt;br /&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//archive/large_deep_networks_nips2012.pdf&quot;&gt;Large Scale Distributed Deep Networks&lt;/a&gt;, by Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark Mao, Marc’aurelio Ranzato, Andrew Senior, Paul Tucker, Ke Yang, Quoc V. Le, Andrew Y. Ng.&lt;br /&gt;&lt;a href=&quot;http://proceedings.mlr.press/v28/coates13.pdf&quot;&gt;Deep Learning with COTS HPC&lt;/a&gt;, Adam Coates, Brody Huval, Tao Wang, David Wu, Bryan Catanzaro, Andrew Ng. ICML 2013. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;모델 병렬화에 특히 관심 있으신 분들을 다음 두 논문들을 보시면 좋으실 겁니다.&lt;br /&gt;&lt;a href=&quot;http://www.cs.cmu.edu/~epxing/papers/2016/Kim_etal_EuroSys16.pdf&quot;&gt;STRADS: A Distributed Framework for Scheduled Model Parallel Machine Learning&lt;/a&gt;, by Jin Kyu Kim, Qirong Ho, Seunghak Lee, Xun Zheng, Wei Dai, Garth A. Gibson, Eric P. Xing. EuroSys 2016.&lt;br /&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.04972&quot;&gt;Device Placement Optimization with Reinforcement Learning&lt;/a&gt;, by Azalia Mirhoseini Lt ; / RTI &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Jinho Lee</name><email>elzinomaster@gmail.com</email></author><category term="deep learning" /><category term="distributed deep learning" /><summary type="html">Intro to Distributed Deep Learning Systems를 번역한 문서입니다.</summary></entry><entry><title type="html">2019 건양 헬스 데이터톤 우승 후기</title><link href="https://elzino.github.io/projects/2019-12-01/konyang-health-datathon" rel="alternate" type="text/html" title="2019 건양 헬스 데이터톤 우승 후기" /><published>2019-12-01T00:00:00+00:00</published><updated>2019-12-01T00:00:00+00:00</updated><id>https://elzino.github.io/projects/2019-12-01/konyang-health-datathon</id><content type="html" xml:base="https://elzino.github.io/projects/2019-12-01/konyang-health-datathon">&lt;p&gt;지난 11월 29일 부터 11월 30일까지 무박 2일로 진행된 &lt;a href=&quot;https://github.com/khd2019/khd2019&quot;&gt;건양 헬스 데이터톤&lt;/a&gt;(Konyang Health Datathon 2019)에 참가했습니다! 이번에도 친구인 승일이와 ‘행복코딩’팀으로 참여했는데요. 이번 대회는 안저 이미지를 정상 안저, 황반 변성, 당뇨성 망막 병증, 망막 정맥 폐쇄 이미지로 분류하는 A조와 유방 촬영 이미지를 양성과 악성으로 분류하는 B조로 나뉘어서 진행되었습니다. 저희는 A조에 참여해 당당히 1등을 하였습니다!! :clap::clap::clap: 대회를 어떻게 준비했는지, 또 어떤걸 느꼈는지 간단히 기록해보려고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.dropbox.com/s/jvg9rfs336liz4z/leaderboard.png?raw=1&quot; alt=&quot;리더보드&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;사전-조사&quot;&gt;사전 조사&lt;/h2&gt;
&lt;p&gt;안저 이미지 분류는 원래 잘 알지 못하던 분야였습니다. 그런데 조사를 해보니 4년전에 &lt;a href=&quot;https://www.kaggle.com/c/diabetic-retinopathy-detection&quot;&gt;Kaggle에서 주관한 대회&lt;/a&gt;도 열렸었고 구글도 &lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/ko//pubs/archive/45732.pdf&quot;&gt;당뇨성 망막 병증을 분류하는 논문&lt;/a&gt;을 냈었습니다. 그래서 대회전에 미리 Kaggle 대회에서 상위팀들의 솔루션 및 관련 논문들을 읽어봤습니다. 이 중에서 Kaggle 1등팀인 Ben Graham의 &lt;a href=&quot;http://blog.kaggle.com/2015/09/09/diabetic-retinopathy-winners-interview-1st-place-ben-graham/&quot;&gt;Gaussian Blur를 이용해 local average를 빼주는 방법&lt;/a&gt;이 인상 깊었습니다.&lt;/p&gt;

&lt;h2 id=&quot;대회&quot;&gt;대회&lt;/h2&gt;
&lt;p&gt;대회를 가서 당황한 부분은 다시 nsml이였습니다. 대회전에 Pytorch를 이용해 베이스 코드를 미리 짜서 갔었는데 nsml에서 도커 이미지 생성에 삼십분 가량이 걸렸습니다. 반면 기본으로 제공하는 Keras를 이용한 코드를 돌려보니 도커 생성이 약 10초만에 되서 대회장에서 Keras를 쓰기로 방향을 틀었습니다.&lt;br /&gt;
대회를 참여하면서 성능을 올리기 위해 여러가지를 시도했습니다. 먼저 저번 NAVER 대회에서 배운 교훈대로 train set과 valid set을 나누는 데 신경을 썼습니다. Category 별로 비율을 맞춰서 train set과 valid set을 나누었습니다. 모델은 VGG-network를 변형해서 사용했고 Keras에서 제공하는 ImageDataGenerator를 이용해 rotation, zoom, width shift, height shift, flip을 시켜서 Augmentation 했습니다. Optimizer는 RAdam을 사용했고 Label smooth도 적용했습니다. 또한 학습 후반부에는 Augmentation을 거의 주지 않고 learning rate와 label smooth 비율을 낮춰서 fine tuning 한 점이 성능 향상에 큰 도움을 주었습니다.&lt;/p&gt;

&lt;h2 id=&quot;느낀점&quot;&gt;느낀점&lt;/h2&gt;
&lt;p&gt;큰 기대를 하지 않고 참여했던 대회인데 좋은 결과가 있어서 너무 기분이 좋았습니다. Keras도 거의 사용해보지 않았었는데 이번 기회에 다루면서 짧은 시간에 모델을 짤때는 확실히 강점이 있음을 느꼈습니다. 다만 Image classification의 경험이 거의 없어서 여러가지를 시도할 때 과연 이게 성능에 도움이 될까? 라는 의구심이 계속 들었습니다. 이론적 기반 없이 동전 던지기를 잘해 성능이 잘 나온 거 같아 좀 더 경험을 쌓아야 할 것 같습니다. 외부 대회에서 처음으로 1등을 해봐서 잊지 못할 추억이 될 것 같습니다. :+1:&lt;/p&gt;</content><author><name>Jinho Lee</name><email>elzinomaster@gmail.com</email></author><category term="hackathon" /><category term="deep learning" /><category term="medical image classification" /><summary type="html">지난 11월 29일 부터 11월 30일까지 무박 2일로 진행된 건양 헬스 데이터톤(Konyang Health Datathon 2019)에 참가했습니다! 이번에도 친구인 승일이와 ‘행복코딩’팀으로 참여했는데요. 이번 대회는 안저 이미지를 정상 안저, 황반 변성, 당뇨성 망막 병증, 망막 정맥 폐쇄 이미지로 분류하는 A조와 유방 촬영 이미지를 양성과 악성으로 분류하는 B조로 나뉘어서 진행되었습니다. 저희는 A조에 참여해 당당히 1등을 하였습니다!! :clap::clap::clap: 대회를 어떻게 준비했는지, 또 어떤걸 느꼈는지 간단히 기록해보려고 합니다.</summary></entry><entry><title type="html">RAdam : On the Variance of the Adaptive Learning Rate and Beyond</title><link href="https://elzino.github.io/papers/2019-11-21/radam" rel="alternate" type="text/html" title="RAdam : On the Variance of the Adaptive Learning Rate and Beyond" /><published>2019-11-21T00:00:00+00:00</published><updated>2019-11-21T00:00:00+00:00</updated><id>https://elzino.github.io/papers/2019-11-21/radam</id><content type="html" xml:base="https://elzino.github.io/papers/2019-11-21/radam">&lt;p&gt;논문 링크 : &lt;a href=&quot;https://arxiv.org/abs/1908.03265&quot;&gt;arxiv&lt;/a&gt;&lt;br /&gt;
저자 코드 : &lt;a href=&quot;https://github.com/LiyuanLucasLiu/RAdam&quot;&gt;Author’s code&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;카카오 블라인드 공채에 지원해서 온라인, 오프라인 코딩테스트를 넘고 나니 회사별 과제가 주어졌습니다. 저는 카카오 브레인에 지원해서, RAdam 논문을 읽고 요약한 뒤 카카오에서 제공한 코드를 개선하라는 과제를 받았습니다. 비록 떨어지긴 했지만(:cry:) 너무나도 재밌는 논문이었습니다. 논문 내용들을 요약해 보았습니다.&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;이 논문에서는 기존 Adaptive learning rate 방법들이 bad local optima에 빠지던 문제가 학습초기에 adpative learning rate의 variance가 크기 때문임을 보입니다.&lt;/li&gt;
  &lt;li&gt;또한 warm-up learning rate 방법도 adpative learning rate의 variance를 줄여서 잘 작동하는 것임을 보입니다.&lt;/li&gt;
  &lt;li&gt;마지막으로 Adaptive learning rate의 variance를 일정하게 만들어주는 RAdam이라는 새로운 방법을 제시합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;variance-of-adaptive-rate-in-the-early-stage&quot;&gt;Variance of adaptive rate in the early stage&lt;/h2&gt;
&lt;p&gt;저자는 학습 초기에 샘플이 부족하기 때문에 adaptive learning rate가 부적절하게 큰 variance를 갖고, 이것이 안좋은 local optima로 이끈다는 것을 수식적으로, 또 실험적으로 보여줍니다.&lt;/p&gt;

&lt;h3 id=&quot;수식적-분석&quot;&gt;수식적 분석&lt;/h3&gt;
&lt;p&gt;저자는 먼저 time-step 마다 얻어지는 gradient들(\({g_1, \cdots, g_t}\))을 모두 정규분포 \( \mathcal{N}(0, \sigma^2)\)에서 i.i.d 하게 뽑힌 random variables 이라고 가정합니다. 가정에 의해 \( \frac{1}{g_1^2} \)은 the scaled inverse chi-squared distribution을 따르게 됩니다. 이때 sample이 1개인 첫번째 adaptive learning rate의 분산을 계산하면 다음의 식이 나옵니다. \[ \mathrm{Var}[\sqrt{\frac{1}{g_1^2}}] \propto \int_0^{\infty} x^{-1} e^{-x} dx \] 이 식을 통해 sample이 1개일 때 adaptive learning rate의 분산이 발산하는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;실험적-분석&quot;&gt;실험적 분석&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://www.dropbox.com/s/fr7w6ghn0moin91/result1.jpg?raw=1&quot; alt=&quot;실험이미지1&quot; width=&quot;600px&quot; /&gt;
저자는 Adam을 warm-up을 적용한 채로, 또 다른 한번은 warm-up을 적용 안한채로 각각 학습하며 iteration마다 gradient 값의 측정해보았습니다. x축은 gradient의 절댓값을 log scale로 나타내었고 그래프의 높이는 frequency를 나타냅니다. 그리고 왼쪽 그래프는 iteration 1번째부터 100번까지의 결과, 오른쪽 그래프는 7만번까지의 결과를 보여줍니다.&lt;br /&gt;
실험 결과를 보면 warm-up 없이 학습한 경우 iteration이 10번도 되기 전에 gradient 값들이 상대적으로 작은 값으로 변형되는 것을 볼 수 있습니다. 이러한 결과는 초기에 bad/suspicious local optima에 빠진다는 것을 의미합니다. warm-up은 초기의 작은 update로 초기에 bad/suspicious local optima에 빠지는 것을 방지합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.dropbox.com/s/tne3ged8gvvjhg3/result2.jpg?raw=1&quot; alt=&quot;실험이미지2&quot; /&gt;
저자는 또한 Adam-2k, RAdam, Adam-eps로도 위 실험을 반복합니다.&lt;br /&gt;
Adam-2k는 처음 2000번 update동안 parameter를 update 시키지 않고 adaptive learing rate만을 계산하는 방법입니다. 따라서 다른 방법들과 비교를 위해 iteration이 -1999번부터 시작된다고 하고 실험을 진행하였습니다. 그 결과 bad local optima에 빠지지 않는 것을 확인 할 수 있습니다. 이는 저자의 가설에서 Adam이 초기에 sample이 부족한 것이 문제의 원인이라는 것을 입증합니다.&lt;br /&gt;
Adam-eps는 adaptive learning rate 식인 \(\hat{\psi}(g_1, \cdots, g_t) = \frac{\sqrt{1-\beta_2^t}}{\epsilon + \sqrt{(1 - \beta_2)\sum_{i = 1}^t \beta_2^{t-i}g_i^2}}\) 에서 엡실론 값을 키워 variance를 낮추는 방법입니다. 이 결과 역시 초기의 bad local optima에 빠지지 않는 것을 보입니다.&lt;/p&gt;

&lt;h2 id=&quot;analysis-of-adaptive-learning-rate-variance&quot;&gt;Analysis of adaptive learning rate variance&lt;/h2&gt;
&lt;p&gt;이번에는 adaptive learning rate의 variance를 구해보고 sample의 수가 늘어날수록 variance가 감소함을 보입니다. 이때 분석의 용이함을 위해 저자는 총 3번의 근사를 시킵니다.  &lt;br /&gt;
첫번째 근사는 exponential moving average를 simple average로 근사시키는 것입니다. 저자는 exponential moving average가 simple average보다 더 큰 분산을 갖을 뿐더러 t가 작을때는 simple average와 차이도 상대적으로 작으므로 이 근사가 무리가 없다고 주장합니다. 
\[p(\psi(.)) = p(\sqrt{\frac{1-\beta_2^t}{(1 - \beta_2)\sum_{i = 1}^t \beta_2^{t-i}g_i^2}}) \approx p(\sqrt{\frac{t}{\sum_{i=1}^t g_i^2}}) \]
\( g_i \sim \mathcal{N}(0, \sigma^2) \)을 가졍했기 때문에 \( \frac{t}{\sum_{i=1}^t g_i^2} \sim Scale–inv–\mathcal{X}^2(t,\frac{1}{\sigma^2}) \) 입니다. 근사 시킨 값이 scaled inverse chi-square 분포를 따르므로 \(\frac{1-\beta_2^t}{(1 - \beta_2)\sum_{i = 1}^t \beta_2^{t-i}g_i^2}\) 또한 자유도 \( \sigma \)를 갖는 scaled inverse chi-square 분포로 가정하겠습니다. 이 가정하에서 저자는 분산을 구합니다.
&lt;img src=&quot;https://www.dropbox.com/s/2dm83bbd7op9t07/Theorem%201.png?raw=1&quot; alt=&quot;Theorem 1&quot; /&gt;
여기서 \( \mathcal{B}(.) \)은 Beta function을 의미합니다. 또한 \( \mathrm{Var}[\psi(.)] \)의 미분 값을 통해 자유도 \( \sigma \)가 증가함에 따라 분산이 단조 감소하는 것을 보입니다. 이로써 학습 초기에 sample이 부족한 것 때문에 나중보다 분산이 크다는 것을 보였습니다.&lt;/p&gt;

&lt;h2 id=&quot;rectified-adaptive-learning-rate&quot;&gt;Rectified adaptive learning rate&lt;/h2&gt;
&lt;p&gt;저자는 앞에서 구한 계산값을 이용해 adaptive learning rate의 분산을 일정하게 만들어주는 방법을 제시합니다. 이를 위해서 먼저 자유도인 \( \sigma \)를 \( t \)를 이용해 구합니다.&lt;/p&gt;

&lt;h3 id=&quot;estimation-of--sigma-&quot;&gt;Estimation of \( \sigma \)&lt;/h3&gt;
&lt;p&gt;자유도를 구하기 위해 두번째 근사를 합니다. 경제학에서 exponential moving average(EMA)는 simple moving average(SMA)로 자주 근사된다고 합니다.
\[ p(\frac{(1 - \beta_2)\sum_{i = 1}^t \beta_2^{t-i}g_i^2}{1-\beta_2^t}) \approx p(\frac{\sum_{i = 1}^{f(t, \beta_2)} g_{t+1-i}^2}{f(t, \beta_2)}) \]
이때 \( f(t, \beta_2) \)는 SMA의 길이로 SMA가 EMA와 같은 “center of mass”를 갖도록 구해집니다. 따라서 \(f(t, \beta_2) = \frac{2}{1 - \beta_2} - 1 - \frac{2 t \beta_2^t}{1 - \beta_2^t}\) 입니다.
\[ \frac{1-\beta_2^t}{(1 - \beta_2)\sum_{i = 1}^t \beta_2^{t-i}g_i^2} \approx \frac{f(t, \beta_2)}{\sum_{i=1}^{f(t, \beta_2)} g_i^2} \sim Scale–inv–\mathcal{X}^2(\rho,\frac{1}{\sigma^2}) \]
\[ \rho \approx f(t, \beta_2) = \frac{2}{1 - \beta_2} - 1 - \frac{2 t \beta_2^t}{1 - \beta_2^t} \]
위와 같이 \( \rho \)의 근사값으로 \( f(t, \beta_2) \)을 이용해 \( t \)에 대한 함수로 표현할 수 있게 되었습니다. 추가로 \( \rho_t = f(t, \beta_2) \)라고 표기했을 때 \( \rho_\infty = \frac{2}{1 - \beta_2} - 1 \)가 됩니다.&lt;/p&gt;

&lt;h3 id=&quot;variance-estimation-and-rectification&quot;&gt;Variance estimation and rectification&lt;/h3&gt;
&lt;p&gt;위에서 분산은 자유도 \( \rho \)가 증가함에 따라 단조감소함을 보였으므로 \( \min_{\rho_t} \mathrm{Var}[\psi(.)] = \mathrm{Var}[\psi(.)]|_ {\rho_t = \rho_\infty} \)이고 이때의 분산을 \( C_{\mbox{var}} \)라고 표기하겠습니다. 저자는 학습 초기의 분산이 커서 bad local optima에 빠지는 문제를 방지하기 위해 매 timestep마다 분산이 \( C_{\mbox{var}} \)가 되도록 아래와 같이 rectification 해줍니다.
\[
  \mathrm{Var}[r_t \,\psi(g_1, \cdots, g_t)] = C_{\mbox{var}}
  \quad
  \mbox{where}
  \quad
  r_t = \sqrt{\frac{C_{\mbox{var}}}{\mathrm{Var}[\psi(g_1, \cdots, g_t)]}}
\]
위에서 \( \mathrm{Var}[\psi(.)] \) 값을 구했지만 수치적으로 불안정하므로 \( \sqrt{\psi^2(.)} \) 에 대한 1차 근사(세번째 근사)를 이용해서 다시 구하면 다음과 같습니다.
\[ \mathrm{Var}[\psi(.)] \approx \frac{\rho_t}{2(\rho_t - 2)(\rho_t - 4)\sigma^2} \]
분산을 \( C_{\mbox{var}} \)로 일정하게 유지시키는 \( r_t \) 값은 다음과 같습니다.
\[
r_t = \sqrt{\frac{(\rho_t - 4)(\rho_t - 2)\rho_\infty}{(\rho_\infty - 4)(\rho_\infty - 2)\rho_t}}
\]
단 \(\rho_t\)가 4보다 작을 경우 adaptive learning rate는 무시합니다. 이를 정리해 적용한 알고리즘은 다음과 같습니다.
&lt;img src=&quot;https://www.dropbox.com/s/lnmad7y7hac01q7/algorithm.png?raw=1&quot; alt=&quot;Algorithm 2&quot; /&gt;
위와 같이 Adam의 분산을 일정하게 만들어주는 방법을 통해 RAdam이라는 새로운 방법을 제안합니다.&lt;/p&gt;
&lt;h3 id=&quot;in-comparison-with-warmup&quot;&gt;In comparison with warmup&lt;/h3&gt;
&lt;p&gt;저자는 \( r_t \)가 결국 gradient에 \( \frac{min(t, T_w)}{T_w} \)을 곱하는 heuristic linear warmup과 비슷한 역할을 한다고 말합니다. 하지만 RAdam은 \( T_w \)와 같은 hyperparameter를 추가로 필요하지 않는 장점이 있습니다. 또한 뒤에서 살펴볼 실험 결과에 따르면 Adam-warmup은 learning rate를 증가시킬 step 수에 따라 learning rate에 민감함을 보이고, RAdam은 robust함을 보입니다.&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;p&gt;저자는 Language Modeling을 평가하기 위해 One Billion Word 데이터셋을, Image Classification을 평가하기 위해 Cifar10 와 ImageNet 데이터셋을 사옹했습니다.&lt;/p&gt;

&lt;h3 id=&quot;radam-vs-vanila-adam-vs-sgd&quot;&gt;RAdam vs Vanila Adam vs SGD&lt;/h3&gt;
&lt;p&gt;저자는 먼저 vanila Adam과 비교해 RAdam이 더 좋은 성능을 내는 것을 보입니다.
&lt;img src=&quot;https://www.dropbox.com/s/fbrghwh9tjiddyq/result3.png?raw=1&quot; alt=&quot;Result1&quot; /&gt;
또한 learning rate의 변화에 robust함을 보입니다.
&lt;img src=&quot;https://www.dropbox.com/s/1u2gbp19lu981zm/result4.png?raw=1&quot; alt=&quot;Result2&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;radam-vs-adam-warmup&quot;&gt;RAdam vs Adam-warmup&lt;/h3&gt;
&lt;p&gt;RAdam은 위에서 말했듯이 Adam-warmup과 달리 처음에 learning rate를 증가시킬 step수를 지정하지 않아도 되므로 hyper-parameter가 하나 더 적습니다. 또한 Adam-warmup은 learning rate를 증가시킬 step 수에 따라 learning rate에 민감함을 보이고, RAdam은 robust함을 보입니다.
&lt;img src=&quot;https://www.dropbox.com/s/l6az85a1i2r8mep/result5.png?raw=1&quot; alt=&quot;Result3&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;느낀점&quot;&gt;느낀점&lt;/h2&gt;
&lt;p&gt;optimization에 관련된 논문은 처음으로 읽어봤습니다. Adam이 나온 이후로 모든 task에 general하게 잘 작동하는 optimizer가 나오지 않은것으로 알고 있습니다. 새로운 시각으로 접근해서 재밌었고 논문에서 이론적 증명을 통해 RAdam의 정당성을 보여준 점이 좋았습니다.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@lessw/new-state-of-the-art-ai-optimizer-rectified-adam-radam-5d854730807b&quot;&gt;New State of the Art AI Optimizer: Rectified Adam (RAdam). - Less Wright&lt;/a&gt;&lt;/p&gt;</content><author><name>Jinho Lee</name><email>elzinomaster@gmail.com</email></author><category term="deep learning" /><category term="optimizer" /><summary type="html">논문 링크 : arxiv 저자 코드 : Author’s code 카카오 블라인드 공채에 지원해서 온라인, 오프라인 코딩테스트를 넘고 나니 회사별 과제가 주어졌습니다. 저는 카카오 브레인에 지원해서, RAdam 논문을 읽고 요약한 뒤 카카오에서 제공한 코드를 개선하라는 과제를 받았습니다. 비록 떨어지긴 했지만(:cry:) 너무나도 재밌는 논문이었습니다. 논문 내용들을 요약해 보았습니다.</summary></entry><entry><title type="html">2019 NAVER AI HACKATHON SPEECH 참가 후기</title><link href="https://elzino.github.io/projects/2019-11-16/naver-ai-hackathon-review" rel="alternate" type="text/html" title="2019 NAVER AI HACKATHON SPEECH 참가 후기" /><published>2019-11-16T00:00:00+00:00</published><updated>2019-11-16T00:00:00+00:00</updated><id>https://elzino.github.io/projects/2019-11-16/naver-ai-hackathon-review</id><content type="html" xml:base="https://elzino.github.io/projects/2019-11-16/naver-ai-hackathon-review">&lt;p&gt;2019년 9월 중순부터 10월 중순까지 약 한 달가량 진행된 &lt;a href=&quot;https://campaign.naver.com/aihackathon_speech/&quot; target=&quot;_blank&quot;&gt;NAVER AI HACATHON&lt;/a&gt;에 참여하였습니다! 이번 해커톤의 주제는 한국어 음성인식으로 네이버에서 공개한 50000쌍의 한국어 전화망 데이터를 이용해 진행하였습니다. 대학교 친구인 &lt;a href=&quot;https://github.com/psi9730&quot; target=&quot;_blank&quot;&gt;박승일&lt;/a&gt;군과 함께 행복코딩 팀으로 참여해 100팀 중 9등이라는 성과를 거두었습니다! 와아~ :clap: 처음 참가해보는 해커톤이였고 음성인식분야도 잘 몰랐었는데 좋은 성적을 거두어서 기분 좋게 마무리 할 수 있었습니다. 참가신청부터 결선까지 어떻게 준비하고 참여하였는지 후기로 남겨보려고 합니다.&lt;/p&gt;

&lt;h2 id=&quot;배경지식-탐색&quot;&gt;배경지식 탐색&lt;/h2&gt;
&lt;p&gt;서류 통과 메일을 받은 후부터 본격적으로 Speech Recognition 분야를 survey 해보았습니다.
제일 먼저 이 부분의 SOTA를 찾아보기위해 &lt;a href=&quot;https://paperswithcode.com/task/speech-recognition&quot; target=&quot;_blank&quot;&gt;Paper with code&lt;/a&gt; 사이트에서 Dataset별로 어떤 연구가 진행되었는지 찾아보았습니다.(Paper with code 짱짱 ㅎㅎ)&lt;br /&gt;
그 후 우선적으로 다음 논문들을 읽어보았습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1412.5567&quot; target=&quot;_blank&quot;&gt;Deep Speech&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.02595&quot; target=&quot;_blank&quot;&gt;Deep Speech 2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1508.01211&quot; target=&quot;_blank&quot;&gt;Listen, Attend and Spell&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1904.08779&quot; target=&quot;_blank&quot;&gt;SpecAugment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;또한 Deep Speech를 만든 바이두에서 강연한 &lt;a href=&quot;https://www.youtube.com/watch?v=9dXiAecyJrY&amp;amp;feature=youtu.be&amp;amp;t=13874&quot; target=&quot;_blank&quot;&gt;영상&lt;/a&gt;이 있는데 기존의 전통적인 Speech Recognition 방식에서 벗어나, 어떻게 딥러닝을 사용해 성공적으로 성능을 끌어 올렸는지 쉽게 설명해주십니다. CTC loss, Language Model 등 Deep Speech에서 사용된 개념뿐만 아니라 음성인식 분야에 전반적인 이해를 돕는 영상이라 처음 이 분야를 공부하시려는 분들한테 강추드립니다! :thumbsup:&lt;br /&gt;
Deep Speech, Deep Speech 2는 CTC loss를 사용하였고 Listen, Attend and Spell은 encoder-decoder 방식을 사용하였습니다. 저는 survey 당시 SOTA였던 SpecAugment 방식을 사용하고 싶었고 Naver에서 제공한 &lt;a href=&quot;https://github.com/clovaai/speech_hackathon_2019&quot; target=&quot;_blank&quot;&gt;baseline code&lt;/a&gt;도 encoder-decoder 방식을 사용하고 있었기 때문에 encoder-decoder 방식을 사용하기로 결정하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;예선&quot;&gt;예선&lt;/h2&gt;
&lt;h4 id=&quot;nsml&quot;&gt;NSML&lt;/h4&gt;
&lt;p&gt;예선이 시작하고 제일 당황스러웠던 것은 로컬에서 잘 돌아가는 모델이 NSML(Naver에서 제공한 딥러닝용 클라우드)에 올리면 잘 안돌아가는 것이였습니다. Librosa 라이브러리를 사용해 mel-spectrogram으로 변환하려고 하였는데 segmentation 오류가 나면서 세션이 죽어버리곤 했습니다. 아무리 디버깅을 해도 이유를 알 수 없어 포기하고 torchaudio를 쓰려던 차에 library간 버전 충돌 때문임을 알고 docker 설정을 바꿔 해결하였습니다.&lt;/p&gt;
&lt;h4 id=&quot;모델-구조-수정-data-전처리-label-smooth&quot;&gt;모델 구조 수정, Data 전처리, label smooth&lt;/h4&gt;
&lt;p&gt;예선 초반에 Listen, Attend and Spell 방식으로 encoder-decoder에 attention을 달고 테스트 해보니 6등으로 출발했습니다. 본선 진출은 문제 없겠다라고 생각했는데 그 이후로 시도하는 것마다 성능 향상을 보이지 못해 28등까지 떨어졌습니다. 이때 이번 해커톤에서 결과를 평가할때 공백을 제거하고 비교하는 점에서 착안해 모델이 아예 공백을 예측하지 않도록 바꾸니 큰 성능향상이 이뤄져서 등수를 많이 올릴 수 있었습니다. 추가로 label smooth, 데이터 전처리(특수문자 제거) 등을 통해서 성능을 더 올려 예선을 8위로 마무리하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;결선&quot;&gt;결선&lt;/h2&gt;
&lt;p&gt;결선은 온라인 결선과 오프라인 결선으로 나누어 진행되었습니다. 온라인 결선에서는 예선에서 제공되었던 3만쌍에 데이터에다 추가로 2만쌍의 데이터가 더 공개되었습니다.&lt;/p&gt;

&lt;h4 id=&quot;오프라인-결선&quot;&gt;오프라인 결선&lt;/h4&gt;
&lt;p&gt;오프라인 결선은 춘천에 있는 네이버 커넥트원 건물에서 진행되었습니다. 처음 들어가자마자 토니 스타크가 살 것 같다고 말했을 만큼 건물이 깔끔하고 멋있게 지어져 있더라고요
&lt;img src=&quot;https://www.dropbox.com/s/vmeb4rs78p8kuo5/%EC%9B%B0%EC%BB%B4%EA%B8%B0%ED%94%84%ED%8A%B8.jpg?raw=1&quot; alt=&quot;네이버 웰컴 기프트&quot; /&gt;
처음 갔을때 받은 명찰과 웰컴 기프트에요! 저 초록색 동그란 건 손목 운동할 때 쓰는 거더라고요.&lt;br /&gt;
&lt;img src=&quot;https://www.dropbox.com/s/mw2thubrnflbt3f/snack.jpg?raw=1&quot; alt=&quot;간식&quot; /&gt;
해커톤 기간동안 무제한으로 먹을 수 있던 간식입니다! 그런데 저 간식 말고도 중간에 떡볶이, 튀김, 콜팝, 치즈볼등 맛있는 간식들을 너무 많이 주셔서 저것들은 별로 안먹었던거 같아요!&lt;br /&gt;
&lt;img src=&quot;https://www.dropbox.com/s/imvo1l9mnjdw35i/lunch.jpg?raw=1&quot; alt=&quot;점심&quot; /&gt;
&lt;img src=&quot;https://www.dropbox.com/s/8uijyxtfsph16pc/dinner.jpg?raw=1&quot; alt=&quot;저녁&quot; /&gt;
점심과 저녁입니다. 정말 정말 맛있었어요 ㅎㅎ 역시 대기업인가 싶더라고요. 덕분에 맛있게 먹고 해커톤에 집중할 수 있었습니다!&lt;br /&gt;
&lt;img src=&quot;https://www.dropbox.com/s/iu4x8s85yq0n4wi/dorm.jpg?raw=1&quot; alt=&quot;숙소&quot; /&gt;
숙소도 너무 좋았어요. 호텔에 와있는 느낌 ㅎㅎ 클로바 스피커도 처음 사용해 봤는데 너무 신기하더라고요. 이번 해커톤 주제가 음성인식이라 더 신기했던거 같아요.&lt;br /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/elzino/naver_ai_hackathon_speech/master/docs/final-board.png&quot; alt=&quot;랭킹&quot; /&gt;&lt;br /&gt;
오프라인 결선 기간 동안 어떻게 모델을 개선할지 고민을 많이 했어요. 결론적으로 예선 기간동안 구현했지만 이상하게 성능이 오르지 않았던 빔서치를 좀 더 살펴보았습니다. 그러던 중 빔서치 로직에서 버그를 찾을 수 있었고 버그를 고치니 인식률이 4퍼센트 가량 올랐습니다! 결국 오프라인 결선 시작할 때 11등까지 떨어졌었는데 다시 올려 9등으로 마무리하였습니다. ㅎㅎ&lt;/p&gt;

&lt;p&gt;오프라인 결선이 끝나고 1, 2, 3등 팀과 질의 응답시간이 있었습니다. librosa를 이용해 음성파일 앞, 뒤에 있는 침묵을 제거했다는 점, naver에서 weight initialization 관련해서 함정코드를 심어놓았다는 점이 인상깊었습니다. 그리고 무엇보다 1등팀이 training set, valid set을 나눌 때 화자, 스크립트를 고려해서 나눈점이 인상깊었습니다. 해커톤 기간 내내 validation error 와 test error가 비례하지 않아서 이상하다고 생각했는데 화자 및 스크립트에 overfitting 된 점이 문제였습니다. 기본이지만 간과하고 있던 부분이였습니다.&lt;/p&gt;

&lt;h2 id=&quot;느낀점&quot;&gt;느낀점&lt;/h2&gt;
&lt;p&gt;이번 해커톤에 참여하여서 처음으로 딥러닝 분야 중 한 task에 몰두해서 모델을 학습시키고 개선해보았습니다. 스피치 분야의 매력도 새롭게 알게 되었고 관심을 갖게 되었습니다.&lt;br /&gt;
또한 성능향상을 위해 모델에만 집중하였는데 결국 모델을 향상시키기 위해선 데이터를 잘 이해하는것이 우선인 것을 다시 한 번 깨닫게 되었습니다. weight initialization과 같은 deep learning의 기본의 중요성도 다시 깨닫게 되었습니다.&lt;br /&gt;
제가 많이 성장할 수 있었고 무엇보다 즐겁게 참여하여서 너무 행복한 시간이였습니다.&lt;br /&gt;
좋은 행사를 마련해준 네이버측에 감사를 표합니다!&lt;/p&gt;

&lt;p&gt;추가로 저희팀의 코드 레포지토리 링크를 첨부합니다&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/elzino/naver_ai_hackathon_speech&quot; target=&quot;_blank&quot;&gt;행복코딩팀의 hackathon code link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jinho Lee</name><email>elzinomaster@gmail.com</email></author><category term="hackathon" /><category term="deep learning" /><category term="speech recognition" /><summary type="html">2019년 9월 중순부터 10월 중순까지 약 한 달가량 진행된 NAVER AI HACATHON에 참여하였습니다! 이번 해커톤의 주제는 한국어 음성인식으로 네이버에서 공개한 50000쌍의 한국어 전화망 데이터를 이용해 진행하였습니다. 대학교 친구인 박승일군과 함께 행복코딩 팀으로 참여해 100팀 중 9등이라는 성과를 거두었습니다! 와아~ :clap: 처음 참가해보는 해커톤이였고 음성인식분야도 잘 몰랐었는데 좋은 성적을 거두어서 기분 좋게 마무리 할 수 있었습니다. 참가신청부터 결선까지 어떻게 준비하고 참여하였는지 후기로 남겨보려고 합니다.</summary></entry></feed>